{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型介绍\n",
    "\n",
    "**Transformer in Transformer**\n",
    "\n",
    "github pytorch代码: [https://github.com/huawei-noah/noah-research/tree/master/TNT](https://github.com/huawei-noah/noah-research/tree/master/TNT)\n",
    "\n",
    "论文地址: [https://arxiv.org/pdf/2103.00112.pdf](https://arxiv.org/pdf/2103.00112.pdf)\n",
    "\n",
    "* \t1. 用于对patch级和pixel级的表征进行建模\n",
    "* \t2. 在每个TNT Block中，outer transformer block用于处理patch embedding，而inner transformer block则从pixel embedding中提取局部特征。\n",
    "* \t3. 通过线性变换层将pixel级特征投影到patch embedding的空间，然后将其添加到patch中\n",
    "* \t4. 嵌套transformer的思想就是先一个Patch， 再对里面的pixel进行transformer\n",
    "*   5. 对于patch而言，每个patch有一个独立的可学习得位置编码，而对于pixel级的序列而言，位置是在patch中相对位置的编码，每个patch的对应位置的pixel的位置编码是相同的\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7efb4a8855594784a93e95e6e15326a5afc8a518c5454100b17048146aef6eee)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/96958dec231445429d7cfcc7a6bc7932eeb010d2b2eb4b248400055114b562b3)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0b2b469436214903895bb3cca68363ba647d317a141d4a2c87e2bbd6bc22d074)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 关于数据集ImageNet\n",
    "\n",
    "ImageNet图像数据集始于2009年，当时李飞飞教授等在CVPR2009上发表了一篇名为《ImageNet: A Large-Scale Hierarchical Image Database》的论文，之后就是基于ImageNet数据集的7届ImageNet挑战赛(2010年开始)，2017年后，ImageNet由Kaggle(Kaggle公司是由联合创始人兼首席执行官Anthony Goldbloom 2010年在墨尔本创立的，主要是为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台)继续维护。\n",
    "\n",
    "本AIStudio项目在线下进行的训练， 所以只使用了验证集进行验证\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1e8613aebb754b96bc799dd3c0c51278da5ab0599e264467912c9e2782821a24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据集解压\n",
    "!mkdir ~/data/ILSVRC2012\n",
    "!tar -xf ~/data/data68594/ILSVRC2012_img_val.tar -C ~/data/ILSVRC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "from paddle.vision.datasets import DatasetFolder, ImageFolder\n",
    "# from paddle.vision.transforms import Compose, Resize, Transpose, Normalize\n",
    "import paddle.vision.transforms as T\n",
    "train_parameters = {\n",
    "    'train_image_dir': '/home/aistudio/data/ILSVRC2012',\n",
    "    'eval_image_dir': '/home/aistudio/data/ILSVRC2012',\n",
    "    'test_image_dir': '/home/aistudio/data/ILSVRC2012',\n",
    "}\n",
    "\n",
    "class CatDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        super(CatDataset, self).__init__()\n",
    "        train_image_dir = train_parameters['train_image_dir']\n",
    "        eval_image_dir = train_parameters['eval_image_dir']\n",
    "        test_image_dir = train_parameters['test_image_dir']\n",
    "\n",
    "        data_transforms = T.Compose([\n",
    "            T.Resize(256, interpolation='bicubic'),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        train_data_folder = DatasetFolder(train_image_dir, transform=data_transforms)\n",
    "        eval_data_folder = DatasetFolder(eval_image_dir, transform=data_transforms)\n",
    "        test_data_folder = ImageFolder(test_image_dir, transform=data_transforms)\n",
    "        self.mode = mode\n",
    "        if self.mode  == 'train':\n",
    "            self.data = train_data_folder\n",
    "        elif self.mode  == 'eval':\n",
    "            self.data = eval_data_folder\n",
    "        elif self.mode  == 'test':\n",
    "            self.data = test_data_folder\n",
    "        print(mode, len(self.data))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index][0].astype('float32')\n",
    "        if self.mode  == 'test':\n",
    "            return data\n",
    "        else:\n",
    "            label = np.array([self.data[index][1]]).astype('int64')\n",
    "            return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型结构搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.nn.initializer import TruncatedNormal, Constant\n",
    "import math\n",
    "import copy\n",
    "import paddle.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# 参数初始化配置\n",
    "trunc_normal_ = TruncatedNormal(std=.02)\n",
    "zeros_ = Constant(value=0.)\n",
    "ones_ = Constant(value=1.)\n",
    "from paddle.io import Dataset\n",
    "\n",
    "# 独立层，即什么操作都没有的网络层\n",
    "class Identity(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, input):\n",
    "        return input\n",
    "\n",
    "class PixelEmbed(nn.Layer):\n",
    "    \"\"\" Image to Pixel Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=16, in_chans=3, in_dim=48, stride=4):\n",
    "        super().__init__()\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        self.img_size = img_size\n",
    "        self.num_patches = num_patches\n",
    "        self.in_dim = in_dim\n",
    "        new_patch_size = math.ceil(patch_size / stride)\n",
    "        self.new_patch_size = new_patch_size\n",
    "        self.proj = nn.Conv2D(in_chans, self.in_dim, kernel_size=7, padding=3, stride=stride)\n",
    "\n",
    "    def forward(self, x, pixel_pos):\n",
    "        B, C, H, W = x.shape\n",
    "        assert H == self.img_size and W == self.img_size, \\\n",
    "            f\"Input image size ({H}*{W}) doesn't match model ({self.img_size}*{self.img_size}).\"\n",
    "        x = self.proj(x)\n",
    "    \n",
    "        x = F.unfold(x, self.new_patch_size, self.new_patch_size)\n",
    "        x = x.transpose((0, 2, 1)).reshape((B * self.num_patches, self.in_dim, self.new_patch_size, self.new_patch_size))\n",
    "        x = x + pixel_pos\n",
    "        x = x.reshape((B * self.num_patches, self.in_dim, -1)).transpose((0, 2, 1))\n",
    "        return x\n",
    "\n",
    "class Attention(nn.Layer):\n",
    "    \"\"\" Multi-Head Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, hidden_dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = hidden_dim // num_heads\n",
    "        self.head_dim = head_dim\n",
    "        self.scale = head_dim ** -0.5\n",
    "\n",
    "        self.qk = nn.Linear(dim, hidden_dim * 2, bias_attr=qkv_bias)\n",
    "        self.v = nn.Linear(dim, dim, bias_attr=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qk = self.qk(x).reshape((B, N, 2, self.num_heads, self.head_dim)).transpose((2, 0, 3, 1, 4))\n",
    "        q, k = qk[0], qk[1]   # make torchscript happy (cannot use tensor as tuple)\n",
    "        v = self.v(x).reshape((B, N, self.num_heads, -1)).transpose((0, 2, 1, 3))\n",
    "\n",
    "        attn = (q @ k.transpose((0, 1, 3, 2))) * self.scale\n",
    "        attn = F.softmax(attn, axis=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose((0, 2, 1, 3)).reshape((B, N, -1))\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class Mlp(nn.Layer):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "def drop_path(x, drop_prob=0., training=False):\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = paddle.to_tensor(1 - drop_prob)\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n",
    "    random_tensor = keep_prob + paddle.rand(shape, dtype=x.dtype)\n",
    "    random_tensor = paddle.floor(random_tensor)  # binarize\n",
    "    output = x.divide(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "\n",
    "class DropPath(nn.Layer):\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "\n",
    "class Block(nn.Layer):\n",
    "    \"\"\" TNT Block\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, in_dim, num_pixel, num_heads=12, in_num_head=4, mlp_ratio=4.,\n",
    "                 qkv_bias=False, drop=0., attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        # Inner transformer\n",
    "        self.norm_in = norm_layer(in_dim)\n",
    "        self.attn_in = Attention(\n",
    "            in_dim, in_dim, num_heads=in_num_head, qkv_bias=qkv_bias,\n",
    "            attn_drop=attn_drop, proj_drop=drop) # attention to check\n",
    "\n",
    "        self.norm_mlp_in = norm_layer(in_dim)\n",
    "        self.mlp_in = Mlp(in_features=in_dim, hidden_features=int(in_dim * 4),\n",
    "                          out_features=in_dim, act_layer=act_layer, drop=drop) #MLP to check\n",
    "\n",
    "        self.norm1_proj = norm_layer(in_dim)\n",
    "        self.proj = nn.Linear(in_dim * num_pixel, dim, bias_attr=True)\n",
    "\n",
    "        # Outer transformer\n",
    "        self.norm_out = norm_layer(dim)\n",
    "        self.attn_out = Attention(\n",
    "            dim, dim, num_heads=num_heads, qkv_bias=qkv_bias,\n",
    "            attn_drop=attn_drop, proj_drop=drop)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else Identity() # to check droppath\n",
    "\n",
    "        self.norm_mlp = norm_layer(dim)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=int(dim * mlp_ratio),\n",
    "                       out_features=dim, act_layer=act_layer, drop=drop)   #MLP to check\n",
    "\n",
    "    def forward(self, pixel_embed, patch_embed):\n",
    "        # inner\n",
    "        pixel_embed = pixel_embed + self.drop_path(self.attn_in(self.norm_in(pixel_embed)))\n",
    "        pixel_embed = pixel_embed + self.drop_path(self.mlp_in(self.norm_mlp_in(pixel_embed)))\n",
    "\n",
    "        # outer\n",
    "        B, N, C = patch_embed.shape\n",
    "        patch_embed[:, 1:] = patch_embed[:, 1:] + self.proj(self.norm1_proj(pixel_embed).reshape((B, N - 1, -1)))\n",
    "        patch_embed = patch_embed + self.drop_path(self.attn_out(self.norm_out(patch_embed)))\n",
    "        patch_embed = patch_embed + self.drop_path(self.mlp(self.norm_mlp(patch_embed)))\n",
    "        return pixel_embed, patch_embed\n",
    "\n",
    "\n",
    "class TNT(nn.Layer):\n",
    "    \"\"\"TNT\"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            img_size=224,\n",
    "            patch_size=16,\n",
    "            in_chans=3,\n",
    "            num_classes=1000,\n",
    "            embed_dim=384,\n",
    "            in_dim=24,\n",
    "            depth=12,\n",
    "            num_heads=6,\n",
    "            in_num_head=4,\n",
    "            mlp_ratio=4.,\n",
    "            qkv_bias=False,\n",
    "            drop_rate=0.,\n",
    "            attn_drop_rate=0.,\n",
    "            drop_path_rate=0.,\n",
    "            norm_layer=nn.LayerNorm,\n",
    "            first_stride=4):\n",
    "        super(TNT, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "        assert img_size % patch_size == 0\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "        self.pixel_embed = PixelEmbed(img_size, patch_size, in_chans, in_dim, first_stride)\n",
    "        num_patches = self.pixel_embed.num_patches\n",
    "        self.num_patches = num_patches\n",
    "        new_patch_size = self.pixel_embed.new_patch_size\n",
    "        num_pixel = new_patch_size ** 2\n",
    "\n",
    "        self.norm1_proj = norm_layer(num_pixel * in_dim)\n",
    "        self.proj = nn.Linear(num_pixel * in_dim, embed_dim)\n",
    "        self.norm2_proj = norm_layer(embed_dim)\n",
    "        self.cls_token = self.create_parameter(shape=(1, 1, embed_dim), default_initializer=zeros_)\n",
    "        self.patch_pos = self.create_parameter(shape=(1, self.num_patches + 1, embed_dim), default_initializer=zeros_)\n",
    "        self.pixel_pos = self.create_parameter(shape=(1, in_dim, new_patch_size, new_patch_size), default_initializer=zeros_)\n",
    "        self.pos_drop = nn.Dropout(1. - drop_rate)\n",
    "\n",
    "        dpr = list(np.linspace(0, drop_rate, depth))\n",
    "        blocks = []\n",
    "        for i in range(depth):\n",
    "            blocks.append(Block(\n",
    "                dim=embed_dim, in_dim=in_dim, num_pixel=num_pixel, num_heads=num_heads, in_num_head=in_num_head,\n",
    "                mlp_ratio=mlp_ratio, qkv_bias=qkv_bias, drop=drop_rate, attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[i], norm_layer=norm_layer))\n",
    "        self.blocks = nn.LayerList(blocks)\n",
    "        self.norm = norm_layer(embed_dim)\n",
    "\n",
    "        self.head = nn.Linear(embed_dim, num_classes) if num_classes > 0 else Identity()\n",
    "\n",
    "        trunc_normal_(self.cls_token)\n",
    "        trunc_normal_(self.patch_pos)\n",
    "        trunc_normal_(self.pixel_pos)\n",
    "\n",
    "    def get_classifier(self):\n",
    "        return self.head\n",
    "\n",
    "    def reset_classifier(self, num_classes, global_pool=''):\n",
    "        self.num_classes = num_classes\n",
    "        self.head = nn.Linear(self.embed_dim, num_classes) if num_classes > 0 else Identity()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "\n",
    "        B = x.shape[0]\n",
    "        pixel_embed = self.pixel_embed(x, self.pixel_pos)\n",
    "\n",
    "        patch_embed = self.norm2_proj(self.proj(self.norm1_proj(pixel_embed.reshape((B, self.num_patches, -1))))) \n",
    "        patch_embed = paddle.concat((self.cls_token.expand((B, -1, -1)), patch_embed), axis=1)\n",
    "        patch_embed = patch_embed + self.patch_pos\n",
    "        patch_embed = self.pos_drop(patch_embed)\n",
    "        for blk in self.blocks:\n",
    "            pixel_embed, patch_embed = blk(pixel_embed, patch_embed)\n",
    "\n",
    "        patch_embed = self.norm(patch_embed)\n",
    "        return patch_embed[:, 0]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  精度对齐\n",
    "\n",
    "因为是简单的图像分类模型，这里只做一个相同输入下的输出结果验证\n",
    "\n",
    "**torch的输出**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f7932104c75e462c9b7dc20466b9fbf7d5fab4861a234e0f92d840e971972327)\n",
    "\n",
    "**paddle的输出**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/b304ef2f36d24353a9656312c02d77a5e8aa6864dd994c51b474e41eb2dca76c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练模型\n",
    "\n",
    "由于训练集特别大, AIStduio暂时还受不了, 这里只用验证集数据训练了两轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 在AIStuido里测试时加载的数据集\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "transforms = T.Compose([\n",
    "    T.Resize(256, interpolation='bicubic'),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    # T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 构建数据集\n",
    "class ILSVRC2012(paddle.io.Dataset):\n",
    "    def __init__(self, root, label_list, transform, backend='pil'):\n",
    "        self.transform = transform\n",
    "        self.root = root\n",
    "        self.label_list = label_list\n",
    "        self.backend = backend\n",
    "        self.load_datas()\n",
    "\n",
    "    def load_datas(self):\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        with open(self.label_list, 'r') as f:\n",
    "            for line in f:\n",
    "                img, label = line[:-1].split(' ')\n",
    "                self.imgs.append(os.path.join(self.root, img))\n",
    "                self.labels.append(int(label))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx]\n",
    "        image = self.imgs[idx]\n",
    "        if self.backend=='cv2':\n",
    "            image = cv2.imread(image)\n",
    "        else:\n",
    "            image = Image.open(image).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        return image.astype('float32'), np.array(label).astype('int64')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "val_dataset = ILSVRC2012('data/ILSVRC2012', transform=transforms, label_list='data/data68594/val_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 391/391 [==============================] - loss: 7.2404 - acc: 7.8000e-04 - 3s/step         \n",
      "save checkpoint at /home/aistudio/checkpoints/0\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 391/391 [==============================] - loss: 7.0968 - acc: 9.8000e-04 - 2s/step         \n",
      "Eval samples: 50000\n",
      "Epoch 2/2\n",
      "step 391/391 [==============================] - loss: 7.1575 - acc: 8.4000e-04 - 2s/step        \n",
      "save checkpoint at /home/aistudio/checkpoints/1\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 391/391 [==============================] - loss: 7.0849 - acc: 9.8000e-04 - 2s/step         \n",
      "Eval samples: 50000\n",
      "save checkpoint at /home/aistudio/checkpoints/final\n"
     ]
    }
   ],
   "source": [
    "#保存训练结果\n",
    "callback = paddle.callbacks.ModelCheckpoint(save_dir='./checkpoints', save_freq=1)\n",
    "\n",
    "#加载模型及预训练参数\n",
    "model = TNT(num_classes=1000)\n",
    "run_model = paddle.Model(model)\n",
    "\n",
    "#模型训练\n",
    "optim = paddle.optimizer.SGD(learning_rate=0.0001, weight_decay=6e-5, parameters=run_model.parameters())\n",
    "run_model.prepare(optimizer= optim,\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())\n",
    "run_model.fit(val_dataset, val_dataset, epochs=2, batch_size=128, callbacks=callback, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 验证模型\n",
    "\n",
    "作者并没有开源源码和更多的信息, 模型验证的结果很难接近论文的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1563/1563 [==============================] - loss: 0.4447 - acc: 0.8141 - 393ms/step         \n",
      "Eval samples: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.44473687], 'acc': 0.81408}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TNT(num_classes=1000)\n",
    "model_state_dict = paddle.load(\"/home/aistudio/work/tnt.pdparams\")\n",
    "model.set_state_dict(model_state_dict)\n",
    "run_model = paddle.Model(model)\n",
    "optim = paddle.optimizer.SGD(learning_rate=0.0001, weight_decay=6e-5, parameters=run_model.parameters())\n",
    "run_model.prepare(optimizer= optim,\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())\n",
    "\n",
    "#模型验证\n",
    "run_model.evaluate(val_dataset, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "因训练硬件资源和时间有限，本次复现过程还有很多缺失和不足，后续持续改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
