{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型介绍\n",
    "\n",
    "**HarDNet: A Low Memory Traffic Network**\n",
    "\n",
    "github pytorch代码: [https://github.com/PingoLH/Pytorch-HarDNet](https://github.com/PingoLH/Pytorch-HarDNet)\n",
    "\n",
    "论文地址: [https://arxiv.org/pdf/1909.00948.pdf](https://arxiv.org/pdf/1909.00948.pdf)\n",
    "- 作者假设中间特征图之间的memory traffic是推理延迟的主要因素\n",
    "- 主要是优化计算量 low MACs， 显存交换memory traffic， 推理时间提升30% ~ 40%\n",
    "- 从动态内存DRAM中加载权重参数比算术操作的功耗更大\n",
    "- 本文着重贡献通过设计cnn, 不以牺牲精度为代价减少特征图DRAM内存交互\n",
    "- 设计了个衡量指标CIO， 卷积层输入输出，大致衡量DRAM交互情况，只适用于计算密度低于某一特定比例。\n",
    "- shortcuts的弊端是加长了tensor的生命周期，导致DRAM和缓存间频繁的数据交换。\n",
    "- k层跟k-2n层连接，形成2的n次方波重叠，当2的n次方层处理完成后就可以清空layer 1. (2的n次方减一)\n",
    "- densenet中每个block层直接反向传播梯度到之前的层，缓解降级，L和L之前的奇数层， HDB结束后其中2到L-2就会立即丢弃，内存专用减少2到3倍。\n",
    "- HDB的每一层都有较宽的输入和较窄的输出，inverting the order会很大增加CIO。DW较大的MAC差异，CIO就不合适。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![](https://ai-studio-static-online.cdn.bcebos.com/f7d634542fdd42f296204a055a9be6a55f25b5b2b5c54fbd88ec5751f55df378)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/90f80bba37a44cdb976370918b0ee50394bd7576e86a4b6ca0bb9a4517945c36)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 关于数据集ImageNet\n",
    "\n",
    "ImageNet图像数据集始于2009年，当时李飞飞教授等在CVPR2009上发表了一篇名为《ImageNet: A Large-Scale Hierarchical Image Database》的论文，之后就是基于ImageNet数据集的7届ImageNet挑战赛(2010年开始)，2017年后，ImageNet由Kaggle(Kaggle公司是由联合创始人兼首席执行官Anthony Goldbloom 2010年在墨尔本创立的，主要是为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台)继续维护。\n",
    "\n",
    "本AIStudio项目在线下进行的训练， 所以只使用了验证集进行验证\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/1e8613aebb754b96bc799dd3c0c51278da5ab0599e264467912c9e2782821a24)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#数据集解压\n",
    "!mkdir ~/data/ILSVRC2012\n",
    "!tar -xf ~/data/data68594/ILSVRC2012_img_val.tar -C ~/data/ILSVRC2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n"
     ]
    }
   ],
   "source": [
    "#加载数据集\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import paddle\n",
    "from paddle.io import Dataset\n",
    "from paddle.vision.datasets import DatasetFolder, ImageFolder\n",
    "# from paddle.vision.transforms import Compose, Resize, Transpose, Normalize\n",
    "import paddle.vision.transforms as T\n",
    "train_parameters = {\n",
    "    'train_image_dir': '/home/aistudio/data/ILSVRC2012',\n",
    "    'eval_image_dir': '/home/aistudio/data/ILSVRC2012',\n",
    "    'test_image_dir': '/home/aistudio/data/ILSVRC2012',\n",
    "}\n",
    "\n",
    "class CatDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        super(CatDataset, self).__init__()\n",
    "        train_image_dir = train_parameters['train_image_dir']\n",
    "        eval_image_dir = train_parameters['eval_image_dir']\n",
    "        test_image_dir = train_parameters['test_image_dir']\n",
    "\n",
    "        data_transforms = T.Compose([\n",
    "            T.Resize(256, interpolation='bicubic'),\n",
    "            T.CenterCrop(224),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        train_data_folder = DatasetFolder(train_image_dir, transform=data_transforms)\n",
    "        eval_data_folder = DatasetFolder(eval_image_dir, transform=data_transforms)\n",
    "        test_data_folder = ImageFolder(test_image_dir, transform=data_transforms)\n",
    "        self.mode = mode\n",
    "        if self.mode  == 'train':\n",
    "            self.data = train_data_folder\n",
    "        elif self.mode  == 'eval':\n",
    "            self.data = eval_data_folder\n",
    "        elif self.mode  == 'test':\n",
    "            self.data = test_data_folder\n",
    "        print(mode, len(self.data))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index][0].astype('float32')\n",
    "        if self.mode  == 'test':\n",
    "            return data\n",
    "        else:\n",
    "            label = np.array([self.data[index][1]]).astype('int64')\n",
    "            return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型结构搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#构建hardet68网络\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from math import ceil\n",
    "from paddle.vision.models import resnet50\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class ConvBNLayer(nn.Layer):\n",
    "    def __init__(self, in_channels, channels, kernel=3, stride=1, pad=0, num_group=1, bias=False, act=\"relu6\"):\n",
    "        super(ConvBNLayer, self).__init__()\n",
    "       \n",
    "        conv_ = None\n",
    "        if stride == 2:\n",
    "            conv_ = nn.Conv2D(in_channels, channels, kernel, stride, [1, 0, 1, 0], groups=num_group, bias_attr=bias)\n",
    "        else:\n",
    "            conv_ = nn.Conv2D(in_channels, channels, kernel, stride, kernel//2, groups=num_group, bias_attr=bias)\n",
    "\n",
    "        bn_ = nn.BatchNorm2D(channels)\n",
    "        act_ = None\n",
    "        if act == 'swish':\n",
    "            act_ = nn.Swish()\n",
    "        elif act == 'relu':\n",
    "            act_ = nn.ReLU()\n",
    "        elif act == 'relu6':\n",
    "            act_ = nn.ReLU6()\n",
    "\n",
    "        self.conv_bn = nn.Sequential(\n",
    "                            conv_,\n",
    "                            bn_\n",
    "                        )\n",
    "\n",
    "        if act_ is not None:\n",
    "            self.conv_bn = nn.Sequential(\n",
    "                                conv_,\n",
    "                                bn_,\n",
    "                                act_\n",
    "                            )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.conv_bn(inputs)\n",
    "\n",
    "class HarDBlock(nn.Layer):\n",
    "\n",
    "    #获取层连接\n",
    "    def get_link(self, layer, base_ch, growth_rate, grmul):\n",
    "        #检查层\n",
    "        if layer == 0:\n",
    "            return base_ch, 0, []\n",
    "        \n",
    "        #计算输出的通道数\n",
    "        out_channels = growth_rate\n",
    "        link = []\n",
    "        for i in range(10):\n",
    "            dv = 2 ** i\n",
    "            if layer % dv == 0: #间隔2的n次方\n",
    "                k = layer - dv\n",
    "                link.append(k)\n",
    "                if i > 0:\n",
    "                    out_channels *= grmul\n",
    "\n",
    "        out_channels = int(int(out_channels + 1) / 2) * 2\n",
    "       \n",
    "\n",
    "        #计算之前层的输出，也就是当前层的输出\n",
    "        in_channels = 0\n",
    "        for i in link:\n",
    "            ch,_,_ = self.get_link(i, base_ch, growth_rate, grmul)\n",
    "            in_channels += ch\n",
    "        return out_channels, in_channels, link\n",
    "\n",
    "    def get_out_ch(self):\n",
    "        return self.out_channels\n",
    "\n",
    "    def __init__(self, in_channels, growth_rate, grmul, n_layers, keepBase=False, residual_out=False, dwconv=False):\n",
    "        super(HarDBlock, self).__init__()\n",
    "\n",
    "        self.keepBase = keepBase\n",
    "        self.links = []\n",
    "        layers_ = []\n",
    "        self.out_channels = 0 # if upsample else in_channels\n",
    "        for i in range(n_layers):\n",
    "            outch, inch, link = self.get_link(i+1, in_channels, growth_rate, grmul)\n",
    "            self.links.append(link)\n",
    "            use_relu = residual_out\n",
    "            layers_.append(ConvBNLayer(inch, outch))\n",
    "            if (i % 2 == 0) or (i == n_layers - 1):\n",
    "                self.out_channels += outch\n",
    "        self.layers = nn.LayerList(layers_)\n",
    "        # print(\"layers: \", len(self.layers))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        layers_ = [x]\n",
    "        \n",
    "        for layer in range(len(self.layers)):\n",
    "            \n",
    "            link = self.links[layer]\n",
    "            # print(\"HarDBlock layer: \", layer, link)\n",
    "            tin = []\n",
    "            for i in link:\n",
    "                tin.append(layers_[i])\n",
    "\n",
    "            if len(tin) > 1:            \n",
    "                x = paddle.concat(x=tin, axis=1)\n",
    "                # print(\"===>concat: \", x.shape)\n",
    "            else:\n",
    "                x = tin[0]\n",
    "            # print(self.layers[layer])\n",
    "            out = self.layers[layer](x)\n",
    "            # print(x.shape, out.shape)\n",
    "            layers_.append(out)\n",
    "            \n",
    "        t = len(layers_)\n",
    "        out_ = []\n",
    "        for i in range(t):\n",
    "          if (i == 0 and self.keepBase) or (i == t-1) or (i%2 == 1):\n",
    "                out_.append(layers_[i])\n",
    "\n",
    "        out = paddle.concat(x=out_, axis=1)\n",
    "        return out\n",
    "\n",
    "class HarDNet68(nn.Layer):\n",
    "    def __init__(self, cls_num=1000):\n",
    "        super(HarDNet68, self).__init__()\n",
    "\n",
    "        #模型的head\n",
    "        base = []\n",
    "        base.append(ConvBNLayer(3, 32, kernel=3, stride=2,  bias=False))\n",
    "        base.append(ConvBNLayer(32, 64, kernel=3))\n",
    "        base.append(nn.MaxPool2D(kernel_size=3, stride=2, padding=1))\n",
    "\n",
    "        #构建HarDBlock\n",
    "        ch_list = [  128, 256, 320, 640, 1024]\n",
    "        gr       = [  14, 16, 20, 40,160]\n",
    "        n_layers = [   8, 16, 16, 16,  4]\n",
    "        downSamp = [   1,  0,  1,  1,  0]\n",
    "        grmul = 1.7\n",
    "        drop_rate = 0.1\n",
    "        blks = len(n_layers)\n",
    "\n",
    "        ch = 64\n",
    "        for i in range(blks):\n",
    "\n",
    "            #blk = self.add_sublayer(\"HarDBlock_\" + str(i), HarDBlock(ch, gr[i], grmul, n_layers[i], dwconv=False))\n",
    "            blk = HarDBlock(ch, gr[i], grmul, n_layers[i], dwconv=False)\n",
    "\n",
    "            ch = blk.get_out_ch()\n",
    "            base.append(blk)\n",
    "            \n",
    "            \n",
    "            # print(\"fucking...===>\", ch, ch_list[i])\n",
    "            base.append(ConvBNLayer(ch, ch_list[i], kernel=1))\n",
    "            # print(self.base[-1])\n",
    "    \n",
    "            ch = ch_list[i]\n",
    "            if downSamp[i] == 1:\n",
    "                base.append(nn.MaxPool2D(kernel_size=2, stride=2))\n",
    "\n",
    "        ch = ch_list[blks-1]\n",
    "        base.append(nn.AdaptiveAvgPool2D(output_size=1))\n",
    "        base.append(nn.Flatten())\n",
    "        base.append(nn.Dropout(drop_rate))\n",
    "        base.append(nn.Linear(ch, cls_num))\n",
    "\n",
    "        self.base = nn.Sequential(*base)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.base):\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#  精度对齐\n",
    "\n",
    "因为是简单的图像分类模型，这里只做一个相同输入下的输出结果验证\n",
    "\n",
    "**torch的最终输出:**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f6bc4c38ba9d4d09a107793f049c3b39bdba95e066114982a29f21c8aad9ea1e)\n",
    "\n",
    "**paddle的最终输出:**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5c2edf3f5ced4471bbcb2040738200076eb7d7cd0b134698bf48c069d6b378d9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练模型\n",
    "\n",
    "由于训练集特别大, AIStduio暂时还受不了, 这里只用验证集数据训练了两轮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 在AIStuido里测试时加载的数据集\r\n",
    "import cv2\r\n",
    "from PIL import Image\r\n",
    "transforms = T.Compose([\r\n",
    "    T.Resize(256, interpolation='bicubic'),\r\n",
    "    T.CenterCrop(224),\r\n",
    "    T.ToTensor(),\r\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\r\n",
    "])\r\n",
    "\r\n",
    "# 构建数据集\r\n",
    "class ILSVRC2012(paddle.io.Dataset):\r\n",
    "    def __init__(self, root, label_list, transform, backend='pil'):\r\n",
    "        self.transform = transform\r\n",
    "        self.root = root\r\n",
    "        self.label_list = label_list\r\n",
    "        self.backend = backend\r\n",
    "        self.load_datas()\r\n",
    "\r\n",
    "    def load_datas(self):\r\n",
    "        self.imgs = []\r\n",
    "        self.labels = []\r\n",
    "        with open(self.label_list, 'r') as f:\r\n",
    "            for line in f:\r\n",
    "                img, label = line[:-1].split(' ')\r\n",
    "                self.imgs.append(os.path.join(self.root, img))\r\n",
    "                self.labels.append(int(label))\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        label = self.labels[idx]\r\n",
    "        image = self.imgs[idx]\r\n",
    "        if self.backend=='cv2':\r\n",
    "            image = cv2.imread(image)\r\n",
    "        else:\r\n",
    "            image = Image.open(image).convert('RGB')\r\n",
    "        image = self.transform(image)\r\n",
    "        return image.astype('float32'), np.array(label).astype('int64')\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.imgs)\r\n",
    "\r\n",
    "val_dataset = ILSVRC2012('data/ILSVRC2012', transform=transforms, label_list='data/data68594/val_list.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dataloader/dataloader_iter.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if isinstance(slot[0], (np.ndarray, np.bool, numbers.Number)):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance.\n",
      "  \"When training, we now always track global mean and variance.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 196/196 [==============================] - loss: 6.9567 - acc: 0.0010 - 3s/step          \n",
      "save checkpoint at /home/aistudio/checkpoints/0\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 196/196 [==============================] - loss: 7.0047 - acc: 8.6000e-04 - 2s/step          \n",
      "Eval samples: 50000\n",
      "Epoch 2/2\n",
      "step 196/196 [==============================] - loss: 7.0444 - acc: 0.0011 - 3s/step          \n",
      "save checkpoint at /home/aistudio/checkpoints/1\n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 196/196 [==============================] - loss: 7.0022 - acc: 0.0010 - 2s/step          \n",
      "Eval samples: 50000\n",
      "save checkpoint at /home/aistudio/checkpoints/final\n"
     ]
    }
   ],
   "source": [
    "#保存训练结果\n",
    "callback = paddle.callbacks.ModelCheckpoint(save_dir='./checkpoints', save_freq=1)\n",
    "\n",
    "#加载模型及预训练参数\n",
    "model = HarDNet68(cls_num=1000)\n",
    "run_model = paddle.Model(model)\n",
    "\n",
    "#模型训练\n",
    "optim = paddle.optimizer.SGD(learning_rate=0.0001, weight_decay=6e-5, parameters=run_model.parameters())\n",
    "run_model.prepare(optimizer= optim,\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())\n",
    "\n",
    "run_model.fit(val_dataset,\n",
    "          val_dataset,\n",
    "          epochs=2,\n",
    "          batch_size=256,\n",
    "          callbacks=callback,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 验证模型\n",
    "\n",
    "验证的最终效果能接近论文的精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 196/196 [==============================] - loss: 0.9377 - acc: 0.7605 - 2s/step          \n",
      "Eval samples: 50000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9376896], 'acc': 0.7605}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HarDNet68(cls_num=1000)\n",
    "model_state_dict = paddle.load(\"/home/aistudio/work/hardnet_best.pdparams\")\n",
    "model.set_state_dict(model_state_dict)\n",
    "run_model = paddle.Model(model)\n",
    "\n",
    "#模型训练\n",
    "optim = paddle.optimizer.SGD(learning_rate=0.0001, weight_decay=6e-5, parameters=run_model.parameters())\n",
    "run_model.prepare(optimizer= optim,\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())\n",
    "run_model.evaluate(val_dataset, batch_size=256, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "因训练硬件资源有限，本次复现过程还有很多缺失和不足，后续持续改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.0.0b0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
